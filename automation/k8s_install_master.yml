---
# https://docs.docker.com/engine/install/ubuntu/
- name: Install K8S
  hosts: k8s_install_master
  become: yes
  gather_facts: yes
  remote_user: ubuntu
  vars:
    # public_ip: 107.22.31.84 
    public_ip: 54.224.126.156
  tasks:
  # - name: Update and upgrade apt packages
  #   apt:
  #     upgrade: "yes"
  #     update_cache: "yes"
  #     cache_valid_time: 86400 # one day
  # - name: install packages
  #   apt:
  #     name: "{{ item }}"
  #     state: present
  #   loop:
  #     - apt-transport-https
  #     - ca-certificates
  #     - curl
  #     - jq
  # - name: Add K8S GPG key
  #   shell: curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
  # - name: set up the stable repository
  #   shell: echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list
  # - name: Update the apt package index
  #   shell: apt update
  # - name: install the latest version of k8s
  # # add -y to auto yes
  #   shell: apt -y install kubeadm kubelet kubectl kubernetes-cni

  # - name: Docker Modifications 
  # # Looks like the latest version of K8s is assuming a “systemd”-based Cgroup driver used by Docker 
  # # because we are using Ubuntu 20.04 now which is using “systemctl” for all the services. 
  # # But default Docker installation is using “cgroupfs” which is causing problems for K8s to start. 
  # # This will fix it (hopefully).
  #   lineinfile:
  #     path: /lib/systemd/system/docker.service
  #     regexp: 'ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock*'
  #     line: ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd
  # - name: restart daemon
  #   shell: systemctl daemon-reload
  # - name: restart docker
  #   shell: systemctl restart docker

  # # Kubernetes will not work unless the swap is turned off; so this is crucial
  # - name: Disabling Swap 
  #   shell: swapoff -a

  # # Ansilbe add line to file https://linuxopsblog.wordpress.com/how-to-add-linessingle-multiple-to-a-file-in-ansible/
  # # modifying my /etc/hosts file on both VMs to add aliases for my existing hostnames

  # - name: getting hostname
  #   shell: hostname
  #   register: cloud_hostname
  #   # the standard output for cloud_hostname is as folows: 
  #   # {'changed': True, 'stdout': 'ip-10-10-2-103', 'stderr': '', 'rc': 0, 'cmd': 'hostname', 
  #   # 'start': '2021-10-22 17:35:39.649426', 'end': '2021-10-22 17:35:39.652546', 'delta': '0:00:00.003120', 
  #   # 'msg': '', 'stdout_lines': ['ip-10-10-2-103'], 'stderr_lines': [], 'failed': False}
  #   # I only want the ip-10-10-2-103 part and it can be accessed just like a normal dictionary
  # - name: add aliass
  #   lineinfile:
  #     path: "/etc/hosts"
  #     # I think it is the private ip instead of the public ip
  #     line: "{{ public_ip }} {{ cloud_hostname['stdout_lines'][0] }} kubemaster kubeworker1"
  #     insertafter: 127.0.0.1 localhost 

# # Work in progress
# From Professor
# do not provide the --apiserver and --control-plane parameters. 
# Just provide the --node-name and --pod-network-cidr params. 
# Make sure to first do sudo kubeadm reset before reissuing the command.
  # - name: Creating the Cluster
  #   shell: "kubeadm init --node-name kubemaster --pod-network-cidr=10.244.0.0/16"

  # # Execute these commands that were output by the kubeadm init command
  # # These are executed on the Master node as normal user (not sudo)
  # # adding the become_user part to do as a normal user
  # - name: kubeadm init command output 1
  #   shell: mkdir -p $HOME/.kube
  #   become_user: ubuntu

  # - name: kubeadm init command output 2
  #   shell: sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  #   become_user: ubuntu

  # - name: kubeadm init command output 3
  #   shell: sudo chown $(id -u):$(id -g) $HOME/.kube/config
  #   become_user: ubuntu

  # - name: validate
  # # The final step effectively makes the normal user own the copied file
  # # the file should be owned by ubuntu
  #   shell: ls -l .kube/
  #   become_user: ubuntu

  # - name: Adding Container Network Virtualization
  # # In order for the cluster nodes and their pods to communicate with each other, 
  # # we need to have a container network virtualization solution
  # # Here we will use Flannel 
  #   shell: kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
  #   become_user: ubuntu

  # - name: Checking the Status Using kubectl
  #   shell: kubectl get pods --all-namespaces
  #   become_user: ubuntu

  # - name: Getting Info about our Cluster
  #   shell: kubectl cluster-info
  #   become_user: ubuntu

  # - name: Checking Current Nodes
  #   shell: kubectl get nodes
  #   become_user: ubuntu

  - name: Allowing Master to Schedule a Pod via Tainting
    shell: kubectl taint nodes kubemaster node-role.kubernetes.io/master:NoSchedule-
    become_user: ubuntu
    
  - name: Check if Tainting is successful
    shell: kubectl get nodes -o json | jq '.items[].spec.taints' 
    become_user: ubuntu
...